{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AditiShelke/100-Days-Of-ML-Code/blob/master/Copy_of_car_collision_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xbK5EqTvGv0"
      },
      "source": [
        "# CS 541-B Assignment 1(B):  Car collision\n",
        "\n",
        "#### Name: Yash Mahesh Kamerkar\n",
        "#### Stevens ID: Enter your Stevens ID here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFe0U5PcvX7B"
      },
      "source": [
        "You have been given a dataset containing the positions of two\n",
        "cars labeled as x1 and x2, along with a ground truth indicator y. In this context,\n",
        "y equals 0 if a collision occurs and 1 if there is no collision. Your task is to create\n",
        "a neural network capable of predicting collisions from scratch, without relying\n",
        "on pre-existing modules."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset 1 **"
      ],
      "metadata": {
        "id": "J-9cd6SiYHOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUUg-Ld9vHdR",
        "outputId": "2a75a3a4-3562-4773-9152-89b3704a3cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 01:07:19--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48252 (47K) [text/plain]\n",
            "Saving to: ‘train.csv.14’\n",
            "\n",
            "\rtrain.csv.14          0%[                    ]       0  --.-KB/s               \rtrain.csv.14        100%[===================>]  47.12K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-02-24 01:07:19 (5.59 MB/s) - ‘train.csv.14’ saved [48252/48252]\n",
            "\n",
            "--2025-02-24 01:07:19--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20695 (20K) [text/plain]\n",
            "Saving to: ‘test.csv.14’\n",
            "\n",
            "test.csv.14         100%[===================>]  20.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-24 01:07:19 (58.1 MB/s) - ‘test.csv.14’ saved [20695/20695]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Download the datset from the below link\n",
        "\"\"\"\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/train.csv'\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/test.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset 2 **"
      ],
      "metadata": {
        "id": "wXVPHnCVYb3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Download the datset from the below link\n",
        "\"\"\"\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_2/train.csv'\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_2/test.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CQHSQ8QYBlB",
        "outputId": "f1452b55-b71a-4ced-a423-808cade18ab0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 01:07:20--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_2/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48312 (47K) [text/plain]\n",
            "Saving to: ‘train.csv.15’\n",
            "\n",
            "\rtrain.csv.15          0%[                    ]       0  --.-KB/s               \rtrain.csv.15        100%[===================>]  47.18K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-02-24 01:07:20 (5.65 MB/s) - ‘train.csv.15’ saved [48312/48312]\n",
            "\n",
            "--2025-02-24 01:07:20--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_2/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20654 (20K) [text/plain]\n",
            "Saving to: ‘test.csv.15’\n",
            "\n",
            "test.csv.15         100%[===================>]  20.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-02-24 01:07:20 (27.3 MB/s) - ‘test.csv.15’ saved [20654/20654]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#Dataset 3\n",
        "    Download the datset from the below link\n",
        "\"\"\"\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_3/train.csv'\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_3/test.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRSLyroIYfJN",
        "outputId": "fcc70c1f-1a4b-4d3d-b798-1be3a331d3a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 01:07:20--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_3/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48188 (47K) [text/plain]\n",
            "Saving to: ‘train.csv.16’\n",
            "\n",
            "\rtrain.csv.16          0%[                    ]       0  --.-KB/s               \rtrain.csv.16        100%[===================>]  47.06K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-02-24 01:07:20 (6.07 MB/s) - ‘train.csv.16’ saved [48188/48188]\n",
            "\n",
            "--2025-02-24 01:07:20--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_3/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20683 (20K) [text/plain]\n",
            "Saving to: ‘test.csv.16’\n",
            "\n",
            "test.csv.16         100%[===================>]  20.20K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-02-24 01:07:20 (33.9 MB/s) - ‘test.csv.16’ saved [20683/20683]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Download the datset from the below link\n",
        "\"\"\"\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_4/train.csv'\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_4/test.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYwA9QFyYl7t",
        "outputId": "c0fd7451-9f92-49c1-cc6e-d2aa100b0c5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 01:07:21--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_4/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48185 (47K) [text/plain]\n",
            "Saving to: ‘train.csv.17’\n",
            "\n",
            "\rtrain.csv.17          0%[                    ]       0  --.-KB/s               \rtrain.csv.17        100%[===================>]  47.06K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-02-24 01:07:21 (5.66 MB/s) - ‘train.csv.17’ saved [48185/48185]\n",
            "\n",
            "--2025-02-24 01:07:21--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_4/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20684 (20K) [text/plain]\n",
            "Saving to: ‘test.csv.17’\n",
            "\n",
            "test.csv.17         100%[===================>]  20.20K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-02-24 01:07:21 (15.0 MB/s) - ‘test.csv.17’ saved [20684/20684]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Download the datset from the below link\n",
        "\"\"\"\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_5/train.csv'\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_5/test.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8VI1240Yn5T",
        "outputId": "bc40219a-2b29-4719-d314-8d38f8e2f013"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 01:07:21--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_5/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48259 (47K) [text/plain]\n",
            "Saving to: ‘train.csv.18’\n",
            "\n",
            "train.csv.18        100%[===================>]  47.13K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-02-24 01:07:21 (5.79 MB/s) - ‘train.csv.18’ saved [48259/48259]\n",
            "\n",
            "--2025-02-24 01:07:21--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_5/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20678 (20K) [text/plain]\n",
            "Saving to: ‘test.csv.18’\n",
            "\n",
            "test.csv.18         100%[===================>]  20.19K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-02-24 01:07:22 (17.8 MB/s) - ‘test.csv.18’ saved [20678/20678]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P8_1BNBCveVg"
      },
      "outputs": [],
      "source": [
        "#For 1st dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset1 = pd.read_csv('train.csv')\n",
        "test_dataset1 = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset2 = pd.read_csv('train.csv.1')\n",
        "test_dataset2 = pd.read_csv('test.csv.1')"
      ],
      "metadata": {
        "id": "QrEEObGLY0jZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset3 = pd.read_csv('train.csv.2')\n",
        "test_dataset3 = pd.read_csv('test.csv.2')"
      ],
      "metadata": {
        "id": "V_vZXdRiY7aE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset4 = pd.read_csv('train.csv.3')\n",
        "test_dataset4 = pd.read_csv('test.csv.3')"
      ],
      "metadata": {
        "id": "j4fQPJW6Y-G6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset5 = pd.read_csv('train.csv.4')\n",
        "test_dataset5 = pd.read_csv('test.csv.4')"
      ],
      "metadata": {
        "id": "uL0NTf1kZA4E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train dataset\n",
        "\n",
        "print(\"Train dataset 1\")\n",
        "print(train_dataset1.head(), \"\\n...\")\n",
        "print(train_dataset1.tail(), \"\\n\")\n",
        "\n",
        "print(\"Train dataset 2\")\n",
        "print(train_dataset2.head(), \"\\n...\")\n",
        "print(train_dataset2.tail(), \"\\n\")\n",
        "\n",
        "print(\"Train dataset 3\")\n",
        "print(train_dataset3.head(), \"\\n...\")\n",
        "print(train_dataset3.tail(), \"\\n\")\n",
        "\n",
        "print(\"Train dataset 4\")\n",
        "print(train_dataset4.head(), \"\\n...\")\n",
        "print(train_dataset4.tail(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1p_j0_lEXdL",
        "outputId": "25ea345a-31bb-49ae-c73a-dbc13023dac9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset 1\n",
            "      x1     x2  y\n",
            "0  2.802  0.093  1\n",
            "1  0.495  0.665  0\n",
            "2  1.512  2.706  1\n",
            "3  0.364  3.297  1\n",
            "4  2.208  4.007  1 \n",
            "...\n",
            "         x1     x2  y\n",
            "3495  1.427  3.013  1\n",
            "3496  2.885  1.206  1\n",
            "3497  0.921  2.046  1\n",
            "3498  4.721  0.108  1\n",
            "3499  0.334  2.494  1 \n",
            "\n",
            "Train dataset 2\n",
            "      x1     x2  y\n",
            "0  2.195  1.308  0\n",
            "1  4.486  0.181  1\n",
            "2  2.185  5.904  1\n",
            "3  1.126  8.251  1\n",
            "4  8.917  3.258  1 \n",
            "...\n",
            "         x1     x2  y\n",
            "3495  6.292  6.518  0\n",
            "3496  1.844  3.679  0\n",
            "3497  3.113  8.880  1\n",
            "3498  2.847  0.378  1\n",
            "3499  8.736  5.656  1 \n",
            "\n",
            "Train dataset 3\n",
            "      x1     x2  y\n",
            "0  0.037  3.758  1\n",
            "1  4.425  0.914  1\n",
            "2  2.173  0.742  1\n",
            "3  0.631  5.104  1\n",
            "4  1.550  4.351  1 \n",
            "...\n",
            "         x1     x2  y\n",
            "3495  1.721  0.550  1\n",
            "3496  2.708  4.016  1\n",
            "3497  5.834  2.493  1\n",
            "3498  4.469  1.356  1\n",
            "3499  5.872  1.613  1 \n",
            "\n",
            "Train dataset 4\n",
            "      x1     x2  y\n",
            "0  6.390  1.895  1\n",
            "1  5.722  4.936  0\n",
            "2  6.608  0.200  1\n",
            "3  4.627  5.031  0\n",
            "4  3.556  3.831  0 \n",
            "...\n",
            "         x1     x2  y\n",
            "3495  4.588  4.690  0\n",
            "3496  6.619  1.323  1\n",
            "3497  1.197  5.552  1\n",
            "3498  4.071  0.106  1\n",
            "3499  5.821  0.852  1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test dataset 1\")\n",
        "print(test_dataset1.head(), \"\\n...\")\n",
        "print(test_dataset1.tail(), \"\\n\")\n",
        "\n",
        "print(\"Test dataset 2\")\n",
        "print(test_dataset2.head(), \"\\n...\")\n",
        "print(test_dataset2.tail(), \"\\n\")\n",
        "\n",
        "print(\"Test dataset 3\")\n",
        "print(test_dataset3.head(), \"\\n...\")\n",
        "print(test_dataset3.tail(), \"\\n\")\n",
        "\n",
        "print(\"Test dataset 4\")\n",
        "print(test_dataset4.head(), \"\\n...\")\n",
        "print(test_dataset4.tail(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se1J6e4ud6Ku",
        "outputId": "230aea54-bc4e-4db2-d5ac-acfbea670872"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset 1\n",
            "      x1     x2  y\n",
            "0  0.793  4.730  1\n",
            "1  2.898  1.469  1\n",
            "2  3.011  4.194  1\n",
            "3  4.217  0.884  1\n",
            "4  4.806  2.731  1 \n",
            "...\n",
            "         x1     x2  y\n",
            "1495  4.478  1.225  1\n",
            "1496  3.086  3.774  1\n",
            "1497  0.272  2.835  1\n",
            "1498  0.538  4.118  1\n",
            "1499  3.911  3.941  0 \n",
            "\n",
            "Test dataset 2\n",
            "      x1     x2  y\n",
            "0  1.158  8.046  1\n",
            "1  3.491  2.942  0\n",
            "2  7.741  2.270  1\n",
            "3  6.787  1.948  1\n",
            "4  4.385  5.686  0 \n",
            "...\n",
            "         x1     x2  y\n",
            "1495  5.936  9.422  1\n",
            "1496  3.384  4.353  0\n",
            "1497  0.705  7.970  1\n",
            "1498  7.668  0.390  1\n",
            "1499  6.264  7.108  0 \n",
            "\n",
            "Test dataset 3\n",
            "      x1     x2  y\n",
            "0  4.205  1.850  1\n",
            "1  5.262  1.354  1\n",
            "2  5.250  5.412  0\n",
            "3  1.688  0.889  0\n",
            "4  2.750  4.496  1 \n",
            "...\n",
            "         x1     x2  y\n",
            "1495  0.479  0.462  0\n",
            "1496  5.719  2.282  1\n",
            "1497  2.556  4.965  1\n",
            "1498  1.987  4.116  1\n",
            "1499  1.461  2.688  1 \n",
            "\n",
            "Test dataset 4\n",
            "      x1     x2  y\n",
            "0  1.509  2.758  0\n",
            "1  2.364  1.950  0\n",
            "2  1.816  5.810  1\n",
            "3  0.953  1.074  0\n",
            "4  5.389  2.830  0 \n",
            "...\n",
            "         x1     x2  y\n",
            "1495  4.326  4.594  0\n",
            "1496  3.180  4.575  0\n",
            "1497  0.946  2.905  0\n",
            "1498  5.299  6.880  0\n",
            "1499  1.598  1.625  0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZHHIVi12KTu",
        "outputId": "19d0d294-28ba-44d9-eaad-883790562bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset 1:\n",
            "Shapes of training data:\n",
            "X_train_1: (3500, 2)\n",
            "y_train_1: (3500,)\n",
            "\n",
            "Shapes of test data:\n",
            "X_test_1: (1500, 2)\n",
            "y_test_1: (1500,)\n",
            "\n",
            "Dataset 2:\n",
            "Shapes of training data:\n",
            "X_train_2: (3500, 2)\n",
            "y_train_2: (3500,)\n",
            "\n",
            "Shapes of test data:\n",
            "X_test_2: (1500, 2)\n",
            "y_test_2: (1500,)\n",
            "\n",
            "Dataset 3:\n",
            "Shapes of training data:\n",
            "X_train_3: (3500, 2)\n",
            "y_train_3: (3500,)\n",
            "\n",
            "Shapes of test data:\n",
            "X_test_3: (1500, 2)\n",
            "y_test_3: (1500,)\n",
            "\n",
            "Dataset 4:\n",
            "Shapes of training data:\n",
            "X_train_4: (3500, 2)\n",
            "y_train_4: (3500,)\n",
            "\n",
            "Shapes of test data:\n",
            "X_test_4: (1500, 2)\n",
            "y_test_4: (1500,)\n",
            "\n",
            "Dataset 5:\n",
            "Shapes of training data:\n",
            "X_train_5: (3500, 2)\n",
            "y_train_5: (3500,)\n",
            "\n",
            "Shapes of test data:\n",
            "X_test_5: (1500, 2)\n",
            "y_test_5: (1500,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of dataset filenames\n",
        "train_files = ['train.csv', 'train.csv.1', 'train.csv.2', 'train.csv.3', 'train.csv.4']\n",
        "test_files = ['test.csv', 'test.csv.1', 'test.csv.2', 'test.csv.3', 'test.csv.4']\n",
        "\n",
        "# Dictionaries to store datasets\n",
        "X_train_dict, X_test_dict, y_train_dict, y_test_dict = {}, {}, {}, {}\n",
        "\n",
        "# Loop through datasets\n",
        "for i, (train_file, test_file) in enumerate(zip(train_files, test_files), start=1):\n",
        "    # Load datasets\n",
        "    train_df = pd.read_csv(train_file)\n",
        "    test_df = pd.read_csv(test_file)\n",
        "\n",
        "    # Extract features and target\n",
        "    X_train_dict[f'X_train_{i}'] = train_df.iloc[:, 0:2].values\n",
        "    y_train_dict[f'y_train_{i}'] = train_df['y'].values\n",
        "    X_test_dict[f'X_test_{i}'] = test_df.iloc[:, 0:2].values\n",
        "    y_test_dict[f'y_test_{i}'] = test_df['y'].values\n",
        "\n",
        "    # Print shapes\n",
        "    print(f\"\\nDataset {i}:\")\n",
        "    print(\"Shapes of training data:\")\n",
        "    print(f\"X_train_{i}:\", X_train_dict[f'X_train_{i}'].shape)\n",
        "    print(f\"y_train_{i}:\", y_train_dict[f'y_train_{i}'].shape)\n",
        "\n",
        "    print(\"\\nShapes of test data:\")\n",
        "    print(f\"X_test_{i}:\", X_test_dict[f'X_test_{i}'].shape)\n",
        "    print(f\"y_test_{i}:\", y_test_dict[f'y_test_{i}'].shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_fmvAnyQof"
      },
      "source": [
        "##Part-1 [15 pts]\n",
        "\n",
        "Implement a class of model, where in the init function, you can initialize the parameters of trainable weights like v11, v12, v21, v22, w1, w2. You can employ PyTorch to initialize them randomly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5wsUKCMLw4WD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af3aa06-179b-4383-8b6d-4078b3515745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset 1:\n",
            "Sample predictions from model_1: [0.23957053 0.40068045 0.19209641 0.23942387 0.10768364]\n",
            "Model parameters for model_1:\n",
            "v11: 0.33669036626815796, v12: 0.12880940735340118\n",
            "v21: 0.23446236550807953, v22: 0.23033303022384644\n",
            "w1: -1.1228563785552979, w2: -0.18632829189300537\n",
            "\n",
            "Dataset 2:\n",
            "Sample predictions from model_2: [0.9486164  0.9952434  0.9850515  0.98976314 0.9999881 ]\n",
            "Model parameters for model_2:\n",
            "v11: 2.2082014083862305, v12: -0.637997031211853\n",
            "v21: 0.46165722608566284, v22: 0.2673508822917938\n",
            "w1: 0.5349046587944031, w2: 0.809357225894928\n",
            "\n",
            "Dataset 3:\n",
            "Sample predictions from model_3: [0.9473916  0.9950362  0.90200204 0.957884   0.7800201 ]\n",
            "Model parameters for model_3:\n",
            "v11: 1.110290288925171, v12: -1.6897989511489868\n",
            "v21: -0.9889599084854126, v22: 0.9579718112945557\n",
            "w1: 1.322135090827942, w2: 0.8171897530555725\n",
            "\n",
            "Dataset 4:\n",
            "Sample predictions from model_4: [0.5        0.32040882 0.5        0.2556191  0.30880216]\n",
            "Model parameters for model_4:\n",
            "v11: -0.765838623046875, v12: -0.7506223320960999\n",
            "v21: 1.3525477647781372, v22: 0.6863219141960144\n",
            "w1: -0.32775864005088806, w2: 0.7949687242507935\n",
            "\n",
            "Dataset 5:\n",
            "Sample predictions from model_5: [0.45874304 0.47067273 0.4551832  0.4833241  0.4832734 ]\n",
            "Model parameters for model_5:\n",
            "v11: 0.2815195620059967, v12: 0.056163541972637177\n",
            "v21: 0.5227160453796387, v22: -0.23835687339305878\n",
            "w1: -0.049903348088264465, w2: 0.5263369679450989\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set random seed\n",
        "seed_value = 42\n",
        "torch.manual_seed(seed_value)\n",
        "\n",
        "# Define the Car_collision class\n",
        "class Car_collision:\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Initialize all the parameters with small random values\n",
        "        '''\n",
        "        self.v11 = torch.randn(1, requires_grad=True)\n",
        "        self.v12 = torch.randn(1, requires_grad=True)\n",
        "        self.v21 = torch.randn(1, requires_grad=True)\n",
        "        self.v22 = torch.randn(1, requires_grad=True)\n",
        "        self.w1 = torch.randn(1, requires_grad=True)\n",
        "        self.w2 = torch.randn(1, requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Compute the forward function\n",
        "        input:\n",
        "            x (input features which contains x1 and x2)\n",
        "        output:\n",
        "            y_pred (the sigmoid score or prediction value)\n",
        "        '''\n",
        "        x1, x2 = x[:, 0], x[:, 1]\n",
        "\n",
        "        # Calculate hidden layer values using ReLU\n",
        "        h1 = F.relu(self.v11 * x1 + self.v21 * x2)\n",
        "        h2 = F.relu(self.v12 * x1 + self.v22 * x2)\n",
        "\n",
        "        # Calculate final output using sigmoid\n",
        "        score = self.w1 * h1 + self.w2 * h2\n",
        "        y_pred = torch.sigmoid(score)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "# Loop through datasets and run model\n",
        "models = {}  # Dictionary to store model instances\n",
        "for i in range(1, 6):  # Loop through 5 datasets\n",
        "    # Convert X_train data to PyTorch tensor\n",
        "    X_train_tensor = torch.tensor(X_train_dict[f'X_train_{i}'], dtype=torch.float32)\n",
        "\n",
        "    # Initialize model for each dataset\n",
        "    models[f'model_{i}'] = Car_collision()\n",
        "\n",
        "    # Run forward pass for each model\n",
        "    y_pred = models[f'model_{i}'].forward(X_train_tensor)\n",
        "\n",
        "    # Print the first few predictions and model details\n",
        "    print(f\"\\nDataset {i}:\")\n",
        "    print(f\"Sample predictions from model_{i}:\", y_pred[:5].detach().numpy())  # Display first 5 predictions\n",
        "    print(f\"Model parameters for model_{i}:\")\n",
        "    print(f\"v11: {models[f'model_{i}'].v11.item()}, v12: {models[f'model_{i}'].v12.item()}\")\n",
        "    print(f\"v21: {models[f'model_{i}'].v21.item()}, v22: {models[f'model_{i}'].v22.item()}\")\n",
        "    print(f\"w1: {models[f'model_{i}'].w1.item()}, w2: {models[f'model_{i}'].w2.item()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcKuMzfH45KS"
      },
      "source": [
        "##Part-2 [15 pts]\n",
        "Implement a training loop that iterates over all the data, computes the gradient scores, updates all weights defined in the Car_collision model, and calculates the average loss obtained from all iterations. You can choose best learning rate, and select epochs number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53iPPsvx1fxh",
        "outputId": "f927faa4-5e6c-4139-d074-16059ac1dd6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on Dataset 1...\n",
            "Epoch 1/30, Loss: 1.1064\n",
            "Epoch 2/30, Loss: 0.5309\n",
            "Epoch 3/30, Loss: 0.5088\n",
            "Epoch 4/30, Loss: 0.5010\n",
            "Epoch 5/30, Loss: 0.4965\n",
            "Epoch 6/30, Loss: 0.4936\n",
            "Epoch 7/30, Loss: 0.4918\n",
            "Epoch 8/30, Loss: 0.4907\n",
            "Epoch 9/30, Loss: 0.4899\n",
            "Epoch 10/30, Loss: 0.4894\n",
            "Epoch 11/30, Loss: 0.4890\n",
            "Epoch 12/30, Loss: 0.4888\n",
            "Epoch 13/30, Loss: 0.4886\n",
            "Epoch 14/30, Loss: 0.4885\n",
            "Epoch 15/30, Loss: 0.4885\n",
            "Epoch 16/30, Loss: 0.4884\n",
            "Epoch 17/30, Loss: 0.4884\n",
            "Epoch 18/30, Loss: 0.4884\n",
            "Epoch 19/30, Loss: 0.4883\n",
            "Epoch 20/30, Loss: 0.4883\n",
            "Epoch 21/30, Loss: 0.4883\n",
            "Epoch 22/30, Loss: 0.4883\n",
            "Epoch 23/30, Loss: 0.4883\n",
            "Epoch 24/30, Loss: 0.4883\n",
            "Epoch 25/30, Loss: 0.4883\n",
            "Epoch 26/30, Loss: 0.4883\n",
            "Epoch 27/30, Loss: 0.4883\n",
            "Epoch 28/30, Loss: 0.4883\n",
            "Epoch 29/30, Loss: 0.4883\n",
            "Epoch 30/30, Loss: 0.4883\n",
            "\n",
            "Training on Dataset 2...\n",
            "Epoch 1/30, Loss: 0.8193\n",
            "Epoch 2/30, Loss: 0.6617\n",
            "Epoch 3/30, Loss: 0.6578\n",
            "Epoch 4/30, Loss: 0.6560\n",
            "Epoch 5/30, Loss: 0.6551\n",
            "Epoch 6/30, Loss: 0.6546\n",
            "Epoch 7/30, Loss: 0.6543\n",
            "Epoch 8/30, Loss: 0.6541\n",
            "Epoch 9/30, Loss: 0.6540\n",
            "Epoch 10/30, Loss: 0.6540\n",
            "Epoch 11/30, Loss: 0.6539\n",
            "Epoch 12/30, Loss: 0.6539\n",
            "Epoch 13/30, Loss: 0.6539\n",
            "Epoch 14/30, Loss: 0.6539\n",
            "Epoch 15/30, Loss: 0.6539\n",
            "Epoch 16/30, Loss: 0.6539\n",
            "Epoch 17/30, Loss: 0.6539\n",
            "Epoch 18/30, Loss: 0.6539\n",
            "Epoch 19/30, Loss: 0.6539\n",
            "Epoch 20/30, Loss: 0.6539\n",
            "Epoch 21/30, Loss: 0.6539\n",
            "Epoch 22/30, Loss: 0.6539\n",
            "Epoch 23/30, Loss: 0.6538\n",
            "Epoch 24/30, Loss: 0.6538\n",
            "Epoch 25/30, Loss: 0.6538\n",
            "Epoch 26/30, Loss: 0.6538\n",
            "Epoch 27/30, Loss: 0.6538\n",
            "Epoch 28/30, Loss: 0.6538\n",
            "Epoch 29/30, Loss: 0.6538\n",
            "Epoch 30/30, Loss: 0.6538\n",
            "\n",
            "Training on Dataset 3...\n",
            "Epoch 1/30, Loss: 0.7522\n",
            "Epoch 2/30, Loss: 0.5899\n",
            "Epoch 3/30, Loss: 0.5897\n",
            "Epoch 4/30, Loss: 0.5897\n",
            "Epoch 5/30, Loss: 0.5897\n",
            "Epoch 6/30, Loss: 0.5897\n",
            "Epoch 7/30, Loss: 0.5897\n",
            "Epoch 8/30, Loss: 0.5897\n",
            "Epoch 9/30, Loss: 0.5897\n",
            "Epoch 10/30, Loss: 0.5897\n",
            "Epoch 11/30, Loss: 0.5897\n",
            "Epoch 12/30, Loss: 0.5897\n",
            "Epoch 13/30, Loss: 0.5897\n",
            "Epoch 14/30, Loss: 0.5897\n",
            "Epoch 15/30, Loss: 0.5897\n",
            "Epoch 16/30, Loss: 0.5897\n",
            "Epoch 17/30, Loss: 0.5897\n",
            "Epoch 18/30, Loss: 0.5897\n",
            "Epoch 19/30, Loss: 0.5897\n",
            "Epoch 20/30, Loss: 0.5896\n",
            "Epoch 21/30, Loss: 0.5896\n",
            "Epoch 22/30, Loss: 0.5896\n",
            "Epoch 23/30, Loss: 0.5896\n",
            "Epoch 24/30, Loss: 0.5896\n",
            "Epoch 25/30, Loss: 0.5896\n",
            "Epoch 26/30, Loss: 0.5896\n",
            "Epoch 27/30, Loss: 0.5896\n",
            "Epoch 28/30, Loss: 0.5896\n",
            "Epoch 29/30, Loss: 0.5896\n",
            "Epoch 30/30, Loss: 0.5896\n",
            "\n",
            "Training on Dataset 4...\n",
            "Epoch 1/30, Loss: 0.7188\n",
            "Epoch 2/30, Loss: 0.6971\n",
            "Epoch 3/30, Loss: 0.6956\n",
            "Epoch 4/30, Loss: 0.6955\n",
            "Epoch 5/30, Loss: 0.6955\n",
            "Epoch 6/30, Loss: 0.6955\n",
            "Epoch 7/30, Loss: 0.6955\n",
            "Epoch 8/30, Loss: 0.6955\n",
            "Epoch 9/30, Loss: 0.6955\n",
            "Epoch 10/30, Loss: 0.6955\n",
            "Epoch 11/30, Loss: 0.6955\n",
            "Epoch 12/30, Loss: 0.6955\n",
            "Epoch 13/30, Loss: 0.6955\n",
            "Epoch 14/30, Loss: 0.6955\n",
            "Epoch 15/30, Loss: 0.6955\n",
            "Epoch 16/30, Loss: 0.6955\n",
            "Epoch 17/30, Loss: 0.6955\n",
            "Epoch 18/30, Loss: 0.6955\n",
            "Epoch 19/30, Loss: 0.6955\n",
            "Epoch 20/30, Loss: 0.6955\n",
            "Epoch 21/30, Loss: 0.6955\n",
            "Epoch 22/30, Loss: 0.6955\n",
            "Epoch 23/30, Loss: 0.6955\n",
            "Epoch 24/30, Loss: 0.6955\n",
            "Epoch 25/30, Loss: 0.6955\n",
            "Epoch 26/30, Loss: 0.6955\n",
            "Epoch 27/30, Loss: 0.6955\n",
            "Epoch 28/30, Loss: 0.6955\n",
            "Epoch 29/30, Loss: 0.6955\n",
            "Epoch 30/30, Loss: 0.6955\n",
            "\n",
            "Training on Dataset 5...\n",
            "Epoch 1/30, Loss: 1.2445\n",
            "Epoch 2/30, Loss: 0.7487\n",
            "Epoch 3/30, Loss: 0.7207\n",
            "Epoch 4/30, Loss: 0.7074\n",
            "Epoch 5/30, Loss: 0.7003\n",
            "Epoch 6/30, Loss: 0.6960\n",
            "Epoch 7/30, Loss: 0.6933\n",
            "Epoch 8/30, Loss: 0.6915\n",
            "Epoch 9/30, Loss: 0.6903\n",
            "Epoch 10/30, Loss: 0.6894\n",
            "Epoch 11/30, Loss: 0.6887\n",
            "Epoch 12/30, Loss: 0.6882\n",
            "Epoch 13/30, Loss: 0.6879\n",
            "Epoch 14/30, Loss: 0.6876\n",
            "Epoch 15/30, Loss: 0.6874\n",
            "Epoch 16/30, Loss: 0.6872\n",
            "Epoch 17/30, Loss: 0.6871\n",
            "Epoch 18/30, Loss: 0.6870\n",
            "Epoch 19/30, Loss: 0.6870\n",
            "Epoch 20/30, Loss: 0.6869\n",
            "Epoch 21/30, Loss: 0.6869\n",
            "Epoch 22/30, Loss: 0.6868\n",
            "Epoch 23/30, Loss: 0.6868\n",
            "Epoch 24/30, Loss: 0.6868\n",
            "Epoch 25/30, Loss: 0.6868\n",
            "Epoch 26/30, Loss: 0.6867\n",
            "Epoch 27/30, Loss: 0.6867\n",
            "Epoch 28/30, Loss: 0.6867\n",
            "Epoch 29/30, Loss: 0.6867\n",
            "Epoch 30/30, Loss: 0.6867\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Define learning rate and number of epochs\n",
        "learning_rate = 2e-4\n",
        "num_epochs = 30\n",
        "\n",
        "# Define the Car_collision model (same as before)\n",
        "class Car_collision:\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Initialize all the parameters with small random values\n",
        "        '''\n",
        "        self.v11 = torch.randn(1, requires_grad=True)\n",
        "        self.v12 = torch.randn(1, requires_grad=True)\n",
        "        self.v21 = torch.randn(1, requires_grad=True)\n",
        "        self.v22 = torch.randn(1, requires_grad=True)\n",
        "        self.w1 = torch.randn(1, requires_grad=True)\n",
        "        self.w2 = torch.randn(1, requires_grad=True)\n",
        "        self.b = torch.randn(1, requires_grad=True)  # Bias term\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Compute the forward function (the output of the model)\n",
        "        input:\n",
        "            x (input features which contains x1 and x2)\n",
        "        output:\n",
        "            y_pred (the sigmoid score or prediction value)\n",
        "        '''\n",
        "        # Extract x1, x2 values\n",
        "        x1, x2 = x[:, 0], x[:, 1]\n",
        "\n",
        "        # Calculate the weighted sum (linear combination)\n",
        "        z1 = self.v11 * x1 + self.v12 * x2\n",
        "        z2 = self.v21 * x1 + self.v22 * x2\n",
        "        z = self.w1 * z1 + self.w2 * z2 + self.b\n",
        "\n",
        "        # Apply the sigmoid activation function to get the probability\n",
        "        y_pred = torch.sigmoid(z)\n",
        "        return y_pred\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        '''\n",
        "        Compute binary cross entropy loss\n",
        "        '''\n",
        "        return F.binary_cross_entropy(y_pred, y_true)\n",
        "\n",
        "# Loop through datasets and train the model\n",
        "for i in range(1, 6):  # Loop through 5 datasets\n",
        "    print(f\"\\nTraining on Dataset {i}...\")\n",
        "\n",
        "    # Convert training data to tensors for the current dataset\n",
        "    X_train_tensor = torch.tensor(X_train_dict[f'X_train_{i}'], dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train_dict[f'y_train_{i}'], dtype=torch.float32)\n",
        "\n",
        "    # Initialize model\n",
        "    model = Car_collision()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for j in range(len(X_train_tensor)):\n",
        "            # Get single training example and convert to tensor\n",
        "            x = X_train_tensor[j:j+1]  # Shape: (1, 2)\n",
        "            y_true = y_train_tensor[j:j+1]  # Shape: (1,)\n",
        "\n",
        "            # Forward pass\n",
        "            y_pred = model.forward(x)\n",
        "\n",
        "            # Compute binary cross entropy loss\n",
        "            loss = model.loss(y_pred, y_true)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update weights using gradient descent\n",
        "            with torch.no_grad():\n",
        "                # Update input-to-hidden layer weights\n",
        "                model.v11 -= model.v11.grad * learning_rate\n",
        "                model.v12 -= model.v12.grad * learning_rate\n",
        "                model.v21 -= model.v21.grad * learning_rate\n",
        "                model.v22 -= model.v22.grad * learning_rate\n",
        "\n",
        "                # Update hidden-to-output layer weights\n",
        "                model.w1 -= model.w1.grad * learning_rate\n",
        "                model.w2 -= model.w2.grad * learning_rate\n",
        "\n",
        "                # Zero all gradients\n",
        "                model.v11.grad.zero_()\n",
        "                model.v12.grad.zero_()\n",
        "                model.v21.grad.zero_()\n",
        "                model.v22.grad.zero_()\n",
        "                model.w1.grad.zero_()\n",
        "                model.w2.grad.zero_()\n",
        "\n",
        "        # Calculate average loss for this epoch\n",
        "        avg_loss = total_loss / len(X_train_tensor)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VotcOjeS5ny9"
      },
      "source": [
        "##Part-4 [5 pts]\n",
        "Implement a loop that iterates over all the test data, predicts scores, and assigns a value of 1 if the score is ~~less~~**greater** than 0.5, otherwise 0.\n",
        "\n",
        "\n",
        "Then calculate the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wvurP0I41hpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9d03da-bce5-4b20-afd6-5a5eeecad7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on Dataset 1...\n",
            "Accuracy on Dataset 1: 0.1920\n",
            "\n",
            "Evaluating on Dataset 2...\n",
            "Accuracy on Dataset 2: 0.4627\n",
            "\n",
            "Evaluating on Dataset 3...\n",
            "Accuracy on Dataset 3: 0.2733\n",
            "\n",
            "Evaluating on Dataset 4...\n",
            "Accuracy on Dataset 4: 0.5533\n",
            "\n",
            "Evaluating on Dataset 5...\n",
            "Accuracy on Dataset 5: 0.5667\n"
          ]
        }
      ],
      "source": [
        "# Evaluation mode\n",
        "with torch.no_grad():\n",
        "    # Loop through datasets and evaluate the model on each\n",
        "    for i in range(1, 6):  # Loop through 5 datasets\n",
        "        print(f\"\\nEvaluating on Dataset {i}...\")\n",
        "\n",
        "        # Get the test data for the current dataset\n",
        "        X_test_tensor = torch.tensor(X_test_dict[f'X_test_{i}'], dtype=torch.float32)\n",
        "        y_test_tensor = torch.tensor(y_test_dict[f'y_test_{i}'], dtype=torch.float32)\n",
        "\n",
        "        # Initialize variables to keep track of accuracy\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Loop through the test data\n",
        "        for j in range(len(X_test_tensor)):\n",
        "            # Get the current sample (ensure x has shape (1, 2))\n",
        "            x = X_test_tensor[j:j+1]  # Shape: (1, 2)\n",
        "            y_true = y_test_tensor[j:j+1]  # Shape: (1,)\n",
        "\n",
        "            # Forward pass: Get prediction\n",
        "            y_pred = model.forward(x)\n",
        "\n",
        "            # Convert prediction to binary: 1 if score >= 0.5, else 0\n",
        "            predicted_label = 1 if y_pred.item() >= 0.5 else 0\n",
        "\n",
        "            # Update total and correct counts\n",
        "            total += 1\n",
        "            correct += (predicted_label == y_true.item())\n",
        "\n",
        "        # Compute accuracy\n",
        "        accuracy = correct / total\n",
        "        print(f\"Accuracy on Dataset {i}: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqtkFHr3ie8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}